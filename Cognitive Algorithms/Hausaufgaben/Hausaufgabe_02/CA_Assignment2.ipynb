{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "",
  "signature": "sha256:a5ca77ca51503f71f008f57e5eea87e7890adb19a639fae61dd2efa91d9adf7b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Cognitive Algorithms - Assignment 2 (30 points)\n",
      "Cognitive Algorithms        \n",
      "Winterterm 2017/2018      \n",
      "Technische Universit\u00e4t Berlin     \n",
      "Fachgebiet Machinelles Lernen \n",
      "\n",
      "**Due on November 16, 2017 10am via ISIS **\n",
      "                   \n",
      "After completing all tasks, run the whole notebook so that the content of each cell is properly displayed. Make sure that the code was ran and the entire output (e.g. figures) is printed. Print the notebook as a PDF file and again make sure that all lines are readable - use line breaks in the Python Code '\\' if necessary. Points will be deducted, if code or content is not readable!                  \n",
      "           \n",
      "**Upload the PDF file that contains a copy of your notebook on ISIS.**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Group:     \n",
      "Members:     "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 1: Multiple Choice Questions (7 points)\n",
      "---\n",
      "In the lecture, you learned about the perceptron and the prototype classifier, which is also called the nearest centroid classifer (NCC).     \n",
      "Please answer questions A) to G) and check the correct answer (using an 'x'). Here is an example:      \n",
      "This is a question?\n",
      "- [ ] wrong answer\n",
      "- [ ] wrong answer\n",
      "- [x] correct answer\n",
      "- [ ] wrong answer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** A) ** The training data for a classification task is given by $ (\\mathbf{x_1}, y_1),\\ldots, ( \\mathbf{x_n}, y_n ) \\in \\mathbb{R}^d \\times \\mathcal{C}$, where $\\mathcal{C}$ is the set of classes and ...:\n",
      "- [ ] ... can be of infinite size\n",
      "- [ ] ... is always defined as $\\mathcal{C} = \\{-1,+1\\}$\n",
      "- [ ] ... neither of the above"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** B) ** The goal of linear classification methods is to learn ...\n",
      "- [ ] a weight vector $\\mathbf{w} \\in \\mathbb{R}^d$ and a bias term $b \\in \\mathbb{R}$\n",
      "- [ ] a weight vector $\\mathbf{w} \\in \\mathbb{R}^n$ and a bias term $b \\in \\mathbb{R}$\n",
      "- [ ] a weight vector $\\mathbf{w} \\in \\mathbb{R}^d$ and a bias term $b \\in \\mathbb{R}^d$\n",
      "- [ ] a weight vector $\\mathbf{w} \\in \\mathbb{R}^n$ and a bias term $b \\in \\mathbb{R}^n$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** C) ** Let $\\mathbf{w}$ be the weight vector. The decision boundary is ...\n",
      "- [ ] orthogonal to $\\mathbf{w}$\n",
      "- [ ] in the same direction as $\\mathbf{w}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** D) ** Let $\\mathbf{w}$ be the weight vector. Which statement is true?\n",
      "- [ ] $\\mathbf{w}$ and $\\mathbf{-w}$ yield the exact same classification result\n",
      "- [ ] $\\mathbf{w}$ and $\\mathbf{-w}$ do not yield the exact same classification result"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** E) ** Let $\\mathbf{w} = (1,1)^T$ and $b = 0$. Let $\\mathbf{x}_1, \\ldots \\mathbf{x_n} \\in \\mathbb{R}^2$ be the training data. Let $i = \\{1, \\ldots ,n \\}$ and $j \\in \\{1, 2\\}$. Which statement is true?\n",
      "- [ ] all data points in the first quadrant ($x_{i,j} > 0$) are classified as $+1$\n",
      "- [ ] all data points in the second quadrant ($x_{i,1} < 0$ and $x_{i,2} > 0$) are classified as $+1$\n",
      "- [ ] all data points in the third quadrant ($x_{i,j} < 0$) are classified as $+1$\n",
      "- [ ] all data points in the fourth quadrant ($x_{i,1} > 0$ and $x_{i,2} < 0$) are classified as $+1$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** F) ** Which statement is true? When ran multiple times on the same data set \n",
      "- [ ] perceptron can yield a different solution in each run\n",
      "- [ ] perceptron yields the same solution in each run"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** G) ** Which statement is true? When ran multiple times on the same data set \n",
      "- [ ] NCC can yield a different solution in each run\n",
      "- [ ] NCC yields the same solution in each run"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 2: Programming (23 points)\n",
      "---\n",
      "The linear perceptron and NCC are linear classification methods. Given training data\n",
      "$$ (\\mathbf{x_1}, y_1),\\ldots, ( \\mathbf{x_n}, y_n ) \\in \\mathbb{R}^d \\times \\{-1,1\\}$$\n",
      "their goal is to learn a weight vector $\\mathbf{w}$ and a bias term $b$, such that each new data point $\\mathbf{x} \\in \\mathbb{R}^d $ will be assigned to the correct class label via the following function:\n",
      "$$ \\mathbf x \\mapsto  \\mbox{sign}(\\mathbf w^T \\cdot \\mathbf x - b). $$\n",
      "\n",
      "\n",
      "The two methods use different strategies to achieve this goal.\n",
      "You will programm and compare the perceptron and the prototype classifier and use them to predict handwritten digits. The task is to classify one digit against all others.         \n",
      "If not done yet, download the data set ```usps.mat``` from the ISIS web site.  \n",
      "Below you can find some useful functions for loading the data and plotting images. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import scipy as sp\n",
      "import scipy.io as io\n",
      "import pylab as pl\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "''' ---- Functions for loading and plotting the images ---- '''\n",
      "def load_usps_data(fname, digit=3):\n",
      "    ''' Loads USPS (United State Postal Service) data from <fname> \n",
      "    Definition:  X, Y = load_usps_data(fname, digit = 3)\n",
      "    Input:       fname   - string\n",
      "                 digit   - optional, integer between 0 and 9, default is 3\n",
      "    Output:      X       -  DxN array with N images with D pixels\n",
      "                 Y       -  1D array of length N of class labels\n",
      "                                 1 - where picture contains the <digit>\n",
      "                                -1 - otherwise                           \n",
      "    '''\n",
      "    # load the data\n",
      "    data = io.loadmat(fname)\n",
      "    # extract images and labels\n",
      "    X = data['data_patterns']\n",
      "    Y = data['data_labels']\n",
      "    Y = Y[digit,:]\n",
      "    return X, Y\n",
      "\n",
      "def plot_img(a):\n",
      "    ''' Plots one image \n",
      "    Definition: plot_img(a) \n",
      "    Input:      a - 1D array that contains an image \n",
      "    '''   \n",
      "    a2 = sp.reshape(a,(int(sp.sqrt(a.shape[0])), int(sp.sqrt(a.shape[0]))))\n",
      "    pl.imshow(a2, cmap='gray') \n",
      "    pl.colorbar()\n",
      "    pl.setp(pl.gca(), xticks=[], yticks=[])\n",
      "            \n",
      "def plot_imgs(X, Y):   \n",
      "    ''' Plots 3 images from each of the two classes \n",
      "    Definition:         plot_imgs(X,Y)\n",
      "    Input:       X       -  DxN array of N pictures with D pixel\n",
      "                 Y       -  1D array of length N of class labels {1, -1}                  \n",
      "    '''\n",
      "    pl.figure()\n",
      "    for i in sp.arange(3):\n",
      "        classpos = (Y == 1).nonzero()[0]\n",
      "        m = classpos[sp.random.random_integers(0, classpos.shape[0]-1)]\n",
      "        pl.subplot(2,3,1+i)\n",
      "        plot_img(X[:, m])\n",
      "    for i in sp.arange(3):\n",
      "        classneg = (Y != 1).nonzero()[0]\n",
      "        m = classneg[sp.random.random_integers(0, classneg.shape[0]-1)]\n",
      "        pl.subplot(2,3,4+i)\n",
      "        plot_img(X[:, m])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,Y = load_usps_data('usps')\n",
      "A = scipy.array([1,2,3])\n",
      "print(size(A))\n",
      "print(len(X))\n",
      "print(len(X[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'scipy' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-8b7daeeeda0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_usps_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'usps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**A) (1 points)**  The data set ```usps.mat``` contains handwritten digits from the U.S. Postal Service data set. Familiarize yourself with the data by loading the data and plotting some images, with the provided functions ```load_usps_data```  and  ```plot_imgs```. Fill in the gaps below. \n",
      "\n",
      "                      \n",
      "The data set contains **[number of images]** images.           \n",
      "Each image consits of **[number of pixels]** pixels. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,Y = load_usps_data('usps')\n",
      "print(len(X))\n",
      "print(len(X[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "256\n",
        "2007\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**B) (6 points)** Implement a linear perceptron by completing the function stub  ```train_perceptron```. We will test three different types of update rules for the learning rate (```option``` $ \\in \\{0,1,2\\}$).\n",
      "$$ \\text{learning rate}(t) = \\begin{cases} \\frac{\\eta}{1+t} & \\text{if} & \\text{option} = 0  \\\\ \\eta & \\text{if} & \\text{option} = 1 \\\\ \\eta \\cdot (1+t) & \\text{if} & \\text{option} = 3 \\end{cases} $$\n",
      "where $t$ is the current iteration and $\\eta$ the initial value of the learning rate.           "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def train_perceptron(X,Y,iterations=200,eta=.1, option=0):\n",
      "    ''' Trains a linear perceptron\n",
      "    Definition:  w, b, acc  = train_perceptron(X,Y,iterations=200,eta=.1)\n",
      "    Input:       X       -  DxN array of N data points with D features\n",
      "                 Y       -  1D array of length N of class labels {-1, 1}\n",
      "                 iter    -  optional, number of iterations, default 200\n",
      "                 eta     -  optional, learning rate, default 0.1\n",
      "                 option  -  optional, defines how eta is updated in each iteration\n",
      "    Output:      w       -  1D array of length D, weight vector \n",
      "                 b       -  bias term for linear classification                          \n",
      "                 acc     -  1D array of length iter, contains classification accuracies \n",
      "                            after each iteration  \n",
      "                            Accuracy = #correctly classified points / N \n",
      "    '''\n",
      "    assert option == 0 or option == 1 or option == 2\n",
      "    acc = sp.zeros((iterations))\n",
      "    #include the bias term by adding a row of ones to X \n",
      "    X = sp.concatenate((sp.ones((1,X.shape[1])), X))\n",
      "    #initialize weight vector\n",
      "    weights = sp.ones((X.shape[0]))/X.shape[0]\n",
      "    for it in sp.arange(iterations):\n",
      "        # indices of misclassified data\n",
      "        wrong = (sp.sign(weights.dot(X)) != Y).nonzero()[0]\n",
      "        # compute accuracy acc[it] (1 point)\n",
      "        # ... your code here\n",
      "        if wrong.shape[0] > 0:\n",
      "            # pick a random misclassified data point (2 points)\n",
      "            # ... your code here\n",
      "            #update weight vector (using different learning rates ) (each 1 point)\n",
      "            if option == 0:\n",
      "                # ... your code here\n",
      "            elif option == 1:\n",
      "                # ... your code here\n",
      "            elif option == 2:\n",
      "                # ... your code here\n",
      "    b = -weights[0] \n",
      "    w = weights[1:]\n",
      "    #return weight vector, bias and accuracies\n",
      "    return w,b,acc\n",
      "\n",
      "''' --------------------------------------------------------------------------------- '''\n",
      "def analyse_accuracies_perceptron(digit = 3, option=0):\n",
      "    ''' Loads usps.mat data and plots digit recognition accuracy in the linear perceptron\n",
      "    Definition: analyse_perceptron(digit = 3)\n",
      "    '''\n",
      "    X,Y = load_usps_data('usps.mat',digit)\n",
      "    w_per,b_per,acc = train_perceptron(X,Y, option=option)\n",
      "    \n",
      "    pl.figure()\n",
      "    pl.plot(sp.arange(len(acc)),acc)\n",
      "    pl.title('Digit recognition accuracy')      \n",
      "    pl.xlabel('Iterations')\n",
      "    pl.ylabel('Accuracy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**C) (4 points)** Call the function ```analyse_accuracies_perceptron``` for a digit of your choice and all three possible ```options```. It plots the classification accuracy, i.e. the percentage of correctly classified data points, as a function of iterations. Answer the following questions:    \n",
      "- Does the accuracy converge (asymptotically)?\n",
      "- What difference do you notice for the different update rules of the learning rate? Try to explain this behaviour.\n",
      "- Which ```option``` would you prefer? Why?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**[Your answer for C]**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analyse_accuracies_perceptron(digit=3, option=0)\n",
      "analyse_accuracies_perceptron(digit=3, option=1)\n",
      "analyse_accuracies_perceptron(digit=3, option=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**D) (3 points)** Implement a Prototype/Nearest Centroid Classifier by completing the function stub ```train_ncc```. Note that points will be deducted for the use of loops. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def train_ncc(X,Y):\n",
      "    ''' Trains a prototype/nearest centroid classifier\n",
      "    Definition:  w, b   = train_ncc(X,Y)\n",
      "    Input:       X       -  DxN array of N data points with D features\n",
      "                 Y       -  1D array of length N of class labels {-1, 1}\n",
      "    Output:      w       -  1D array of length D, weight vector  \n",
      "                 b       -  bias term for linear classification                          \n",
      "    '''\n",
      "    # ... your code here "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**E) (4 points)** Complete the function stub ```plot_histogram``` that calculates the classification accuracy and plots a histogram of classifier output $\\mathbf w^T \\mathbf x$ for each class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def plot_histogram(X, Y, w, b):\n",
      "    ''' Plots a histogram of classifier outputs (w^T X) for each class with pl.hist \n",
      "    The title of the histogram is the accuracy of the classification\n",
      "    Accuracy = #correctly classified points / N \n",
      "    \n",
      "    Definition:     plot_histogram(X, Y, w, b)\n",
      "    Input:          X       -  DxN array of N data points with D features\n",
      "                    Y       -  1D array of length N of class labels\n",
      "                    w       -  1D array of length D, weight vector \n",
      "                    b       -  bias term for linear classification   \n",
      "    \n",
      "    '''\n",
      "    # ... your code here \n",
      "    \n",
      "''' --------------------------------------------------------------------------------- '''\n",
      "def compare_classifiers(digit = 3):\n",
      "    ''' Loads usps.mat data, trains the perceptron and the Nearest centroid classifiers, \n",
      "    and plots their weight vector and classifier output\n",
      "    Definition: compare_classifiers(digit = 3)\n",
      "    '''\n",
      "    X,Y = load_usps_data('usps.mat',digit)\n",
      "    w_ncc,b_ncc = train_ncc(X,Y)\n",
      "    w_per,b_per,_ = train_perceptron(X,Y)\n",
      "    \n",
      "    pl.figure()\n",
      "    pl.subplot(2,2,1)\n",
      "    plot_img(w_ncc)\n",
      "    pl.title('NCC')\n",
      "    pl.subplot(2,2,3)\n",
      "    plot_histogram(X, Y, w_ncc, b_ncc)\n",
      "    \n",
      "    pl.subplot(2,2,2)\n",
      "    plot_img(w_per)\n",
      "    pl.title('Perceptron')\n",
      "    pl.subplot(2,2,4)\n",
      "    plot_histogram(X, Y, w_per, b_per)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**F) (4 points)** Call ```compare_classifiers``` for a digit of your choice. It plots, for both the perceptron and the nearest centroid classifier, the histogram of classifier outputs and the weight vector. Call the function several times for different digits and answer the following questions:\n",
      "- Do you notice a performance difference for the different digits? Why could this be? \n",
      "- Show the histograms of the digits with highest difference in accuracy. \n",
      "- Which algorithm (Nearest Centroid Classifier or Perceptron) would you prefer for this task? Why?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**[Your answer for F]**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# ... your code for F) here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**G) (1 points)**  In this task, you have trained and tested the algorithm on the same data set. Is this enough to reach a final conclusion on which algorithms performs good on this type of data? Why?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**[Your answer for G]**"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}